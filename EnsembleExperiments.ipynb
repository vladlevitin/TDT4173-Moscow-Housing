{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_area(dataset):\n",
    "    small = dataset[dataset[\"area_total\"] < 70]\n",
    "    big = dataset[dataset[\"area_total\"] >= 70]\n",
    "    return small, big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training data\n",
    "train_data = dfTrain.copy()\n",
    "# split data on area total \n",
    "train_data_small, train_data_big = split_area(train_data)\n",
    "\n",
    "train_data_small = process_data(train_data_small, keep_col=['price'], remove_col=['rooms', 'phones', 'new', 'elevator_without', 'elevator_passenger', 'elevator_service', 'district']) \n",
    "train_data_big = process_data(train_data_big, keep_col=['price'], remove_col=['rooms', 'phones', 'new', 'elevator_without', 'elevator_passenger', 'elevator_service', 'district']) \n",
    "\n",
    "def fit_predict_lgbm(training_dataset):\n",
    "    # split training data into test and training split\n",
    "    X_train, X_test = train_test_split(training_dataset, test_size=0.1, random_state=42)\n",
    "\n",
    "    # get price columns \n",
    "    y_train = X_train.pop(\"price\")\n",
    "    y_test = X_test.pop(\"price\")\n",
    "\n",
    "    cols = X_train.columns\n",
    "\n",
    "    # log prices\n",
    "    y_train = np.log(y_train)\n",
    "\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    imputor=IterativeImputer(\n",
    "        estimator=BayesianRidge(),\n",
    "        imputation_order='ascending', \n",
    "        max_iter=100,\n",
    "        tol=1e-5)\n",
    "\n",
    "    X_train = imputor.fit_transform(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "\n",
    "    X_test = imputor.fit_transform(X_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    lgbm_regressor = lgb.LGBMRegressor(\n",
    "        num_leaves=52,\n",
    "        max_depth=75, \n",
    "        random_state=42,\n",
    "        metric='rmse',\n",
    "        n_jobs=4, \n",
    "        n_estimators=3640,\n",
    "        colsample_bytree=0.48432530282059805,\n",
    "        subsample=0.9272124012179532,\n",
    "        learning_rate=0.05084923664278231\n",
    "    )\n",
    "\n",
    "    lgbm_regressor.fit(X_train, y_train, early_stopping_rounds=100, eval_set=[(X_test, y_test)])\n",
    "\n",
    "    lgbm_prediction = lgbm_regressor.predict(X_test)\n",
    "    lgbm_prediction = np.exp(lgbm_prediction)\n",
    "\n",
    "    lgbm_rmsle = round(np.sqrt(mean_squared_log_error(lgbm_prediction, y_test)), 4)\n",
    "    print('Test RMSLE:', lgbm_rmsle)\n",
    "\n",
    "    # red is real prices, green is predicted prices\n",
    "    plt.figure(figsize=(50, 10))\n",
    "    plt.plot(y_test.values[:500], color = 'red')\n",
    "    plt.plot(lgbm_prediction[:500], color = 'green')\n",
    "    plt.show()\n",
    "\n",
    "    # correct predictions are on the diagonal\n",
    "    plt.scatter(lgbm_prediction, y_test, s=2)\n",
    "    plt.xlabel('LightGBM prediction')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.show()\n",
    "\n",
    "    importances = lgbm_regressor.feature_importances_\n",
    "    forest_importances = pd.Series(importances, index=cols)\n",
    "    fig, ax=plt.subplots(1, 1, figsize=(14,6))\n",
    "    forest_importances.plot.bar(ax=ax)\n",
    "    ax.set_title(\"Gini Importance\")\n",
    "    ax.set_ylabel(\"Importance\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return lgbm_regressor, lgbm_prediction, lgbm_rmsle, y_test\n",
    "\n",
    "\n",
    "lgbm_regressor_small, lgbm_prediction_small, lgbm_rmsle_small, y_test_small = fit_predict_lgbm(train_data_small)\n",
    "lgbm_regressor_big, lgbm_prediction_big, lgbm_rmsle_big, y_test_big = fit_predict_lgbm(train_data_big)\n",
    "\n",
    "# concatinate small and big apartments predictions and truth values\n",
    "lgbm_prediction = np.concatenate((lgbm_prediction_small, lgbm_prediction_big), axis=0)\n",
    "y_test = np.concatenate((y_test_small, y_test_big), axis=0)\n",
    "\n",
    "lgbm_rmsle = round(np.sqrt(mean_squared_log_error(lgbm_prediction, y_test)), 4)\n",
    "print('Test RMSLE:', lgbm_rmsle)\n",
    "\n",
    "# red is real prices, green is predicted prices\n",
    "plt.figure(figsize=(50, 10))\n",
    "plt.plot(y_test.tolist()[:500], color = 'red')\n",
    "plt.plot(lgbm_prediction[:500], color = 'green')\n",
    "plt.show()\n",
    "\n",
    "# correct predictions are on the diagonal\n",
    "plt.scatter(lgbm_prediction, y_test, s=2)\n",
    "plt.xlabel('LightGBM prediction')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.show()\n",
    "\n",
    "# 0.154 \n",
    "# 0.139 log\n",
    "# 0.131 log + all_features + rmsle\n",
    "# 0.131 log + all_features + rmse\n",
    "# 0.132 log + all_features-(prison, airport)\n",
    "# 0.132 log + all_features + keep_high_prices\n",
    "# 0.129 -||- hyperparameter optimized\n",
    "# 0.127 -||- hyperparameter optimized v2\n",
    "# 0.111 0.03 test split\n",
    "# 0.128 -||- 0.1 split, even more features\n",
    "# 0.136 -||- only center\n",
    "\n",
    "# 0.1290 all \n",
    "# 0.1258 remove=('rooms', 'phones', 'new', 'elevator_without', 'elevator_passenger', 'elevator_service')\n",
    "# 0.1250 remove=('rooms', 'phones', 'new', 'elevator_without', 'elevator_passenger', 'elevator_service', 'district')\n",
    "\n",
    "# 0.1256 added early stop\n",
    "# 0.1252 without category type\n",
    "\n",
    "# 0.1266 altered distance features+olympic\n",
    "# 0.1261 reverted some alterations\n",
    "# 0.1273\n",
    "\n",
    "# 0.1252\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
